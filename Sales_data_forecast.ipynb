{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54cc8a8b",
   "metadata": {},
   "source": [
    "## This code is to analyze and experiment with the sales data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f866fb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commonly used python functions and display settings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # specify to ignore warning messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa6a566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key imports for this code (various ML and Stat Models)\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.tsa.api import ExponentialSmoothing\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from statsmodels.tsa.stattools import pacf\n",
    "import pmdarima as pm\n",
    "from pmdarima import model_selection\n",
    "from pmdarima import auto_arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3225d2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import viz libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "plotly.offline.init_notebook_mode(connected=True)\n",
    "from plotly.graph_objs import *\n",
    "from plotly import tools\n",
    "import plotly.graph_objects as go\n",
    "from matplotlib import pyplot\n",
    "from pandas.plotting import autocorrelation_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5bf964",
   "metadata": {},
   "source": [
    "### Get data and analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c184d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch data from the CSV file\n",
    "sales_data = pd.read_csv('prod2store3sales.csv', parse_dates = ['Date'])\n",
    "\n",
    "sales_data.head()\n",
    "sales_data.tail()\n",
    "\n",
    "# Finding how many rows of data we have and if there are any NaN values\n",
    "len(sales_data)\n",
    "sales_data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fad1672",
   "metadata": {},
   "source": [
    "## While analyzing, we will use only the first 600 data points reserving the remaining for testing which technically is not observable IRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99770d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a plot of sales made over time\n",
    "plot_data = []\n",
    "plot_data.append(go.Scatter(x= sales_data['Date'][0:600], y= sales_data['Units Sold'][0:600]))\n",
    "layout = go.Layout(xaxis = dict(title='Date'), yaxis = dict(title= 'Units Sold'), \n",
    "                   title = 'Time Series of Daily Units Sold in Training Data')\n",
    "fig = go.Figure(data= plot_data, layout=layout)\n",
    "\n",
    "plotly.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b284428f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zooming into the first three weeks of data from the above plot\n",
    "plot_data = []\n",
    "plot_data.append(go.Scatter(x= sales_data['Date'][0:21], y= sales_data['Units Sold'][0:21]))\n",
    "layout = go.Layout(xaxis = dict(title='Date'), yaxis = dict(title= 'Units Sold'), \n",
    "                   title = 'Time Series of Daily Units Sold in Training Data')\n",
    "fig = go.Figure(data= plot_data, layout=layout)\n",
    "\n",
    "plotly.offline.iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90270ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates a graph of the autocorrelation function versus lags for the sales data\n",
    "sm.graphics.tsa.plot_acf(sales_data['Units Sold'][0:600].values.squeeze(), lags=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512bf551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates a graph of the partial autocorrelation function versus lags for the calls data\n",
    "sm.graphics.tsa.plot_pacf(sales_data['Units Sold'][0:600].values.squeeze(), lags=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9e1256",
   "metadata": {},
   "source": [
    "## Adding Lag Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1547725a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since there is no trending, we are not going to detrend\n",
    "# But we will use use season of 1 week (7 days) and also use previous day's sales\n",
    "sales_data['lag1 sales'] = sales_data['Units Sold'].shift(periods = 1)\n",
    "sales_data['lag7 sales'] = sales_data['Units Sold'].shift(periods = 7)\n",
    "# Due to the shift, the first 7 rows will have NaN that we drop\n",
    "sales_data.dropna(inplace = True)\n",
    "sales_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f711d964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 'Weather Condition' column is categorical; what are the categories? \n",
    "set(sales_data['Weather Condition'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3933176",
   "metadata": {},
   "source": [
    "### Initially let us ignore the date and month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a009add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dummy variables and dropping first of the 4 types (does not add value here)\n",
    "sales_data = pd.get_dummies(sales_data, drop_first=True) \n",
    "sales_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb07d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We reset our index so our datafra starts with index 0\n",
    "sales_data.reset_index(drop = True, inplace = True)\n",
    "sales_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2e1da1",
   "metadata": {},
   "source": [
    "## Uncomment following if we wish to add month and day-of-week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e774b4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # We can use the dates and day-of-week as features\n",
    "# sales_data['month'] = sales_data['Date'].dt.month\n",
    "# sales_data['day'] = sales_data['Date'].dt.weekday\n",
    "# sales_data.head()\n",
    "# sales_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d93e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split the data into a training set and a testing set\n",
    "train_data = sales_data[sales_data['Date'] < '2023-10-01']\n",
    "test_data = sales_data[sales_data['Date'] >= '2023-10-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cc559d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating training data dropping columns not needed and also ground truth\n",
    "X_train = train_data.drop(columns = ['Date', 'Units Sold'])\n",
    "y_train = train_data['Units Sold']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671ffb86",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acdc976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model and parameters\n",
    "gb = GradientBoostingRegressor(n_estimators = 100, max_depth = 6, min_samples_leaf = 2)\n",
    "# Asking the model to fit the training data\n",
    "gb = gb.fit(X_train, y_train) \n",
    "# Asking what the importance of features\n",
    "gb.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b13996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the testing data sets\n",
    "X_test = test_data.drop(columns = ['Date', 'Units Sold'])\n",
    "y_test = test_data['Units Sold']\n",
    "# Make predictions\n",
    "y_preds = gb.predict(X_test)\n",
    "# Calculate percentage and absolute errors\n",
    "perc_errors = np.abs(y_test-y_preds)/y_test\n",
    "abs_errors = np.abs(y_test-y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c74b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the percentage-error results\n",
    "print('Mean absolute percentage error:', np.mean(perc_errors))\n",
    "print('Median absolute percentage error:', np.median(perc_errors))\n",
    "print('75th percentile of absolute percentage error:', np.percentile(perc_errors, 75))\n",
    "print('90th percentile of absolute percentage error:', np.percentile(perc_errors, 90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ace901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the absolute error ratio results\n",
    "avg_test = test_data['Units Sold'].mean()\n",
    "print('Mean absolute error ratio:', np.mean(abs_errors)/avg_test)\n",
    "print('Median absolute error ratio:', np.median(abs_errors)/avg_test)\n",
    "print('75th percentile absolute error ratio:', np.percentile(abs_errors, 75)/avg_test)\n",
    "print('90th percentile absolute error ratio:', np.percentile(abs_errors, 90)/avg_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a94a68",
   "metadata": {},
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eec9ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the XGBoost regressor with specific hyperparameters\n",
    "model = XGBRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.2,\n",
    "        subsample=1.0,\n",
    "        colsample_bytree=1.0,\n",
    "        objective='reg:squarederror',\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c15199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_preds = model.predict(X_test)\n",
    "# Calculate percentage and absolute errors\n",
    "perc_errors = np.abs(y_test-y_preds)/y_test\n",
    "abs_errors = np.abs(y_test-y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7903b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the percentage-error results\n",
    "print('Mean absolute percentage error:', np.mean(perc_errors))\n",
    "print('Median absolute percentage error:', np.median(perc_errors))\n",
    "print('75th percentile of absolute percentage error:', np.percentile(perc_errors, 75))\n",
    "print('90th percentile of absolute percentage error:', np.percentile(perc_errors, 90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f78901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the absolute error ratio results\n",
    "avg_test = test_data['Units Sold'].mean()\n",
    "print('Mean absolute error ratio:', np.mean(abs_errors)/avg_test)\n",
    "print('Median absolute error ratio:', np.median(abs_errors)/avg_test)\n",
    "print('75th percentile absolute error ratio:', np.percentile(abs_errors, 75)/avg_test)\n",
    "print('90th percentile absolute error ratio:', np.percentile(abs_errors, 90)/avg_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa2fc27",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20e41b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model and parameters\n",
    "rf = RandomForestRegressor(max_depth = 6, min_samples_leaf = 2, max_features = \"sqrt\")\n",
    "# Asking the model to fit the training data\n",
    "rf = rf.fit(X_train, y_train) \n",
    "# Asking what the importance of features\n",
    "rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5f91a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_preds = rf.predict(X_test)\n",
    "# Calculate percentage and absolute errors\n",
    "perc_errors = np.abs(y_test-y_preds)/y_test\n",
    "abs_errors = np.abs(y_test-y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb29ea31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the percentage-error results\n",
    "print('Mean absolute percentage error:', np.mean(perc_errors))\n",
    "print('Median absolute percentage error:', np.median(perc_errors))\n",
    "print('75th percentile of absolute percentage error:', np.percentile(perc_errors, 75))\n",
    "print('90th percentile of absolute percentage error:', np.percentile(perc_errors, 90))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8762e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the absolute error ratio results\n",
    "avg_test = test_data['Units Sold'].mean()\n",
    "print('Mean absolute error ratio:', np.mean(abs_errors)/avg_test)\n",
    "print('Median absolute error ratio:', np.median(abs_errors)/avg_test)\n",
    "print('75th percentile absolute error ratio:', np.percentile(abs_errors, 75)/avg_test)\n",
    "print('90th percentile absolute error ratio:', np.percentile(abs_errors, 90)/avg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974d91ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
